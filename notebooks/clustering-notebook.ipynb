{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77e1a47-cb6f-4c0a-a913-4e9604101d69",
   "metadata": {},
   "source": [
    "---\n",
    "title: Clustering Notebook\n",
    "date: 2025-01-30\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a126b19-834a-4aab-95a2-30f44bc7abef",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78cd293-8af6-4020-bbc9-2e6204dce737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import skimage\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b5af6-4372-4046-b725-b51f7b4ecda7",
   "metadata": {},
   "source": [
    "## Load Data and Data Curation: general way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63acb66d-2d4f-4d11-9d36-a6ea643136b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filedir = \"data/\"\n",
    "# zenodo_url = \"https://zenodo.org/record/4555979/files/\"\n",
    "\n",
    "# model_files = [\n",
    "#     'Sm_0_1_HAADF.h5',\n",
    "#     'Sm_0_1_UCParameterization.h5',\n",
    "#     'Sm_7_0_HAADF.h5',\n",
    "#     'Sm_7_0_UCParameterization.h5',\n",
    "#     'SM_10_0_HAADF.h5',\n",
    "#     'Sm_10_0_UCParameterization.h5',\n",
    "#     'Sm_13_0_HAADF.h5',\n",
    "#     'Sm_13_0_UCParameterization.h5',\n",
    "#     'Sm_20_1_HAADF.h5',\n",
    "#     'Sm_20_1_UCParameterization.h5'\n",
    "# ]\n",
    "\n",
    "# for model_file in model_files:\n",
    "    \n",
    "#     file_name = os.path.join(filedir, model_file)\n",
    "#     zenodo_name = zenodo_url + model_file + \"?download=1\"\n",
    "    \n",
    "#     print(file_name)\n",
    "#     if os.path.exists(file_name):\n",
    "#         continue\n",
    "    \n",
    "#     wget.download(zenodo_name, out=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d33492-ec43-4381-b424-df07f4df2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #image files\n",
    "# composition_tags = [0,7,10,13,20]    #Sm composition %\n",
    "\n",
    "\n",
    "# img_filename = ['Sm_0_1_HAADF.h5',\n",
    "#                 'Sm_7_0_HAADF.h5',\n",
    "#                 'SM_10_0_HAADF.h5',\n",
    "#                 'Sm_13_0_HAADF.h5',\n",
    "#                 'Sm_20_1_HAADF.h5']\n",
    "\n",
    "# imnum = len(img_filename)\n",
    "\n",
    "# #paramterization files\n",
    "\n",
    "# UCparam_filename = ['Sm_0_1_UCParameterization.h5',\n",
    "#                     'Sm_7_0_UCParameterization.h5',\n",
    "#                     'Sm_10_0_UCParameterization.h5',\n",
    "#                     'Sm_13_0_UCParameterization.h5',\n",
    "#                     'Sm_20_1_UCParameterization.h5']\n",
    "\n",
    "# #load parameter files\n",
    "# UCparam = []\n",
    "# for x in UCparam_filename:\n",
    "#   print('loading parameterization file: ', os.path.join(filedir, x))\n",
    "#   temp = h5py.File(os.path.join(filedir, x), 'r')\n",
    "#   UCparam.append(temp)\n",
    "\n",
    "# #load images\n",
    "# imgdata = []\n",
    "# for x in img_filename:\n",
    "#   print('loading image file: ', os.path.join(filedir, x))\n",
    "#   temp = h5py.File(os.path.join(filedir, x), 'r')['MainImage']\n",
    "#   imgdata.append(temp)\n",
    "\n",
    "# print('UC parameterization:', [k for k in UCparam[0].keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa84d68-4951-4079-8015-6739e4ae0166",
   "metadata": {},
   "source": [
    "## Physical descriptors: polarization, strain, lattice parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a92d92-0aad-4007-85fb-96ed8ef2af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function maps x,y grid positions into a matrix data format\n",
    "# def map2grid(inab, inVal):\n",
    "\n",
    "#   default_val = np.nan\n",
    "#   abrng = [int(np.min(inab[:,0])), int(np.max(inab[:,0])), int(np.min(inab[:,1])), int(np.max(inab[:,1]))]\n",
    "#   abind = inab\n",
    "#   abind[:,0] -= abrng[0]\n",
    "#   abind[:,1] -= abrng[2]\n",
    "#   Valgrid = np.empty((abrng[1]-abrng[0]+1,abrng[3]-abrng[2]+1))\n",
    "#   Valgrid[:] = default_val\n",
    "#   Valgrid[abind[:,0].astype(int),abind[:,1].astype(int)]=inVal[:]\n",
    "#   return Valgrid, abrng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a256434a-60d1-4c79-b02d-a4e33eed5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBFOdata = []     #this will be the output list of dictionaries for each dataset\n",
    "\n",
    "# for i in np.arange(imnum):\n",
    "#   temp_dict = {'Index': i}\n",
    "#   temp_dict['Composition'] = composition_tags[i]\n",
    "#   temp_dict['Image'] = imgdata[i]\n",
    "#   temp_dict['Filename'] = img_filename[i]\n",
    "\n",
    "#   for k in UCparam[i].keys():       #add labels for UC parameterization\n",
    "#     temp_dict[k] = UCparam[i][k][()]\n",
    "\n",
    "#   #select values mapped to ab grid\n",
    "#   temp_dict['ab_a'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['ab'][()].T[:,0])[0]       #a array\n",
    "#   temp_dict['ab_b'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['ab'][()].T[:,1])[0]       #b array\n",
    "#   temp_dict['ab_x'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['xy_COM'][()].T[:,0])[0]   #x array\n",
    "#   temp_dict['ab_y'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['xy_COM'][()].T[:,1])[0]   #y array\n",
    "#   temp_dict['ab_Px'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['Pxy'][0])[0]             #Px array\n",
    "#   temp_dict['ab_Py'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['Pxy'][1])[0]        #Py array\n",
    "#   temp_dict['Vol'] = map2grid(UCparam[i]['ab'][()].T, UCparam[i]['Vol'])[0]     #Vol array\n",
    "\n",
    "#   SBFOdata.append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb3f51d-f520-479a-8109-b0f0c08642f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the main area to be highlighted with a red square\n",
    "# main = [1000, 3000, 400, 2400]  # [y_start, y_end, x_start, x_end]\n",
    "\n",
    "# # Example: Resizing ab_Px and ab_Py, and plotting the selected region\n",
    "# for i in np.arange(imnum):\n",
    "#     img_shape = SBFOdata[i][\"Image\"].shape  # Target shape\n",
    "#     px_shape = SBFOdata[i][\"ab_Px\"].shape  # Current shape of ab_Px\n",
    "#     py_shape = SBFOdata[i][\"ab_Py\"].shape  # Current shape of ab_Py\n",
    "\n",
    "#     # Calculate the zoom factor for resizing ab_Px and ab_Py\n",
    "#     zoom_factors_px = [img_shape[0] / px_shape[0], img_shape[1] / px_shape[1]]\n",
    "#     zoom_factors_py = [img_shape[0] / py_shape[0], img_shape[1] / py_shape[1]]\n",
    "\n",
    "#     # Resize ab_Px and ab_Py to match the Image shape and ensure they are exactly the same size\n",
    "#     SBFOdata[i][\"ab_Px_resized\"] = zoom(SBFOdata[i][\"ab_Px\"], zoom_factors_px, order=1)\n",
    "#     SBFOdata[i][\"ab_Py_resized\"] = zoom(SBFOdata[i][\"ab_Py\"], zoom_factors_py, order=1)\n",
    "\n",
    "#     # Ensure the resized arrays match the image shape exactly (if rounding issues occur)\n",
    "#     SBFOdata[i][\"ab_Px_resized\"] = SBFOdata[i][\"ab_Px_resized\"][:img_shape[0], :img_shape[1]]\n",
    "#     SBFOdata[i][\"ab_Py_resized\"] = SBFOdata[i][\"ab_Py_resized\"][:img_shape[0], :img_shape[1]]\n",
    "\n",
    "# Create figure with subplots for the selected data points\n",
    "# fig, ax = plt.subplots(nrows=3, ncols=5, figsize=(3*5, 3*3), dpi=200)\n",
    "\n",
    "# for j, idx in enumerate(np.arange(imnum)):\n",
    "#     k = SBFOdata[idx]\n",
    "\n",
    "#     # Image - select the region\n",
    "#     selected_image = k['Image'][main[0]:main[1], main[2]:main[3]]\n",
    "#     ax[0, j].imshow(selected_image, origin='upper', cmap='gray')\n",
    "#     ax[0, j].set_title(f\"{k['Index']}: {k['Composition']}%\", fontsize=24, fontweight=\"bold\")\n",
    "#     ax[0, j].set_axis_off()\n",
    "#     ax[0, j].invert_yaxis()\n",
    "\n",
    "#     # Px - select the region\n",
    "#     selected_px = k['ab_Px_resized'][main[0]:main[1], main[2]:main[3]]\n",
    "#     ax[1, j].imshow(selected_px, origin='upper', cmap='jet')\n",
    "#     ax[1, j].set_axis_off()\n",
    "#     ax[1, j].invert_yaxis()\n",
    "\n",
    "#     # Py - select the region\n",
    "#     selected_py = k['ab_Py_resized'][main[0]:main[1], main[2]:main[3]]\n",
    "#     ax[2, j].imshow(selected_py, origin='upper', cmap='jet')\n",
    "#     ax[2, j].set_axis_off()\n",
    "#     ax[2, j].invert_yaxis()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9efb5808-782e-46c5-862d-bcbb415b5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create new lists to store the selected images, Px, and Py data\n",
    "# selected_images = []\n",
    "# ground_truth_px = []\n",
    "# ground_truth_py = []\n",
    "\n",
    "# # Define the main area to be highlighted\n",
    "# main = [1000, 3000, 400, 2400]  # [y_start, y_end, x_start, x_end]\n",
    "\n",
    "# # Loop over the selected indices, extract the region, and store it\n",
    "# for i in np.arange(imnum):\n",
    "#     k = SBFOdata[i]\n",
    "\n",
    "#     # Select the region from the image, Px, and Py\n",
    "#     selected_image = k['Image'][main[0]:main[1], main[2]:main[3]]\n",
    "#     selected_px = k['ab_Px_resized'][main[0]:main[1], main[2]:main[3]]\n",
    "#     selected_py = k['ab_Py_resized'][main[0]:main[1], main[2]:main[3]]\n",
    "\n",
    "#     # Append the selected regions to the corresponding lists\n",
    "#     selected_images.append(selected_image)\n",
    "#     ground_truth_px.append(selected_px)\n",
    "#     ground_truth_py.append(selected_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee00ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert lists to NumPy arrays with lower precision (float32) to reduce size\n",
    "# selected_images_array = np.array(selected_images, dtype=np.float32)\n",
    "# ground_truth_px_array = np.array(ground_truth_px, dtype=np.float32)\n",
    "# ground_truth_py_array = np.array(ground_truth_py, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b875ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I will now display a confirmation of the stored data.\n",
    "# print(len(selected_images), len(ground_truth_px), len(ground_truth_py))\n",
    "\n",
    "# images_data = \"/Users/kbarakat/variational-autoencoders/notebooks/data/images_data.pkl\"\n",
    "# with open(images_data, \"wb\") as f:\n",
    "#     pickle.dump((selected_images, ground_truth_px, ground_truth_py), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8a906",
   "metadata": {},
   "source": [
    "## Load preaquired data for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99e93e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fd8c69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kbarakat/miniconda3/envs/ferro_VAE/lib/python3.12/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ByJf-0aq9NLZdxYzcyZifnWan92xc4CP\n",
      "From (redirected): https://drive.google.com/uc?id=1ByJf-0aq9NLZdxYzcyZifnWan92xc4CP&confirm=t&uuid=f4fcda30-f2cd-4bb3-a2eb-5d554624018b\n",
      "To: /Users/kbarakat/variational-autoencoders/notebooks/images_data.pkl\n",
      "100%|████████████████████████████████████████| 480M/480M [00:30<00:00, 15.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "! gdown --fuzzy --id 1ByJf-0aq9NLZdxYzcyZifnWan92xc4CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32b02aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5\n"
     ]
    }
   ],
   "source": [
    "# Load the lists from the pickle file\n",
    "images_data = \"/Users/kbarakat/variational-autoencoders/notebooks/images_data.pkl\"\n",
    "\n",
    "with open(images_data, \"rb\") as f:\n",
    "    selected_images, ground_truth_px, ground_truth_py = pickle.load(f)\n",
    "\n",
    "# Confirm successful loading by checking the lengths of the lists\n",
    "print(len(selected_images), len(ground_truth_px), len(ground_truth_py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea932216-1749-4380-a9e6-ce9dd978ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization:\n",
    "def norm2d(img: np.ndarray) -> np.ndarray:\n",
    "    return (img - np.min(img)) / (np.max(img) - np.min(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab7f4b3-20d3-4dc9-bd8d-63fafc2c041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_extract_subimages(imgdata, coordinates, w_prime):\n",
    "    # Stage 1: Extract subimages with a fixed size (64x64)\n",
    "    large_window_size = (64, 64)\n",
    "    half_height_large = large_window_size[0] // 2\n",
    "    half_width_large = large_window_size[1] // 2\n",
    "    subimages_largest = []\n",
    "    coms_largest = []\n",
    "\n",
    "    for coord in coordinates:\n",
    "        cx = int(np.around(coord[0]))\n",
    "        cy = int(np.around(coord[1]))\n",
    "        top = max(cx - half_height_large, 0)\n",
    "        bottom = min(cx + half_height_large, imgdata.shape[0])\n",
    "        left = max(cy - half_width_large, 0)\n",
    "        right = min(cy + half_width_large, imgdata.shape[1])\n",
    "\n",
    "        subimage = imgdata[top:bottom, left:right]\n",
    "        if subimage.shape[0] == large_window_size[0] and subimage.shape[1] == large_window_size[1]:\n",
    "            subimages_largest.append(subimage)\n",
    "            coms_largest.append(coord)\n",
    "\n",
    "    # Stage 2: Use these centers to extract subimages of window size `w1`\n",
    "    half_height = w_prime[0] // 2\n",
    "    half_width = w_prime[1] // 2\n",
    "    subimages_target = []\n",
    "    coms_target = []\n",
    "\n",
    "    for coord in coms_largest:\n",
    "        cx = int(np.around(coord[0]))\n",
    "        cy = int(np.around(coord[1]))\n",
    "        top = max(cx - half_height, 0)\n",
    "        bottom = min(cx + half_height, imgdata.shape[0])\n",
    "        left = max(cy - half_width, 0)\n",
    "        right = min(cy + half_width, imgdata.shape[1])\n",
    "\n",
    "        subimage = imgdata[top:bottom, left:right]\n",
    "        if subimage.shape[0] == w_prime[0] and subimage.shape[1] == w_prime[1]:\n",
    "            subimages_target.append(subimage)\n",
    "            coms_target.append(coord)\n",
    "\n",
    "    return np.array(subimages_target), np.array(coms_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ae99bb-d9c1-4dfd-886b-eea525555442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_descriptor(window_size, min_sigma, max_sigma, threshold, overlap):\n",
    "\n",
    "    processed_img = img\n",
    "\n",
    "    all_atoms = skimage.feature.blob_log(processed_img, min_sigma, max_sigma, 30, threshold, overlap)\n",
    "    coordinates = all_atoms[:, : -1]\n",
    "    # Extract subimages\n",
    "    subimages_target, coms_target = custom_extract_subimages(processed_img, coordinates, window_size)\n",
    "    # Build descriptors\n",
    "    descriptors = [subimage.flatten() for subimage in subimages_target]\n",
    "    descriptors = np.array(descriptors)\n",
    "\n",
    "    return descriptors, coms_target, all_atoms, coordinates, subimages_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "330cc339-e3f0-46e1-b339-a1106c21459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Fit_GMM_param function without PCA, including covariance type\n",
    "def Fit_GMM(descriptors, components, covariance_type):\n",
    "    # First pass of GMM to estimate initial parameters\n",
    "\n",
    "    # Flatten each subimage into a 1D vector\n",
    "    flattened_descriptors = descriptors.reshape(descriptors.shape[0], -1)\n",
    "    # Remove subimages with NaN values\n",
    "    mask = ~np.isnan(flattened_descriptors).any(axis=1)\n",
    "    valid_subimages = flattened_descriptors[mask]\n",
    "\n",
    "    preliminary_gmm = GaussianMixture(n_components=components, covariance_type=covariance_type, random_state=42)\n",
    "    preliminary_gmm.fit(valid_subimages)\n",
    "    initial_means = preliminary_gmm.means_\n",
    "    initial_weights = preliminary_gmm.weights_\n",
    "\n",
    "    # Initialize and fit the GMM using the parameters from the preliminary GMM\n",
    "    gmm = GaussianMixture(n_components=components,\n",
    "                          means_init=initial_means,\n",
    "                          weights_init=initial_weights,\n",
    "                          covariance_type=covariance_type,\n",
    "                          random_state=42)\n",
    "\n",
    "    gmm.fit(valid_subimages)\n",
    "\n",
    "    # Map the labels back to the original data, including NaN-handling\n",
    "    labels = gmm.predict(valid_subimages)\n",
    "\n",
    "    full_labels = np.full(valid_subimages.shape[0], -1)\n",
    "    full_labels[mask] = labels\n",
    "\n",
    "    return labels, valid_subimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33cf4da6-0bff-4340-b5d6-29949dcea654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fit_PCA_GMM(descriptors, n_clusters, components, covariance_type):\n",
    "\n",
    "    # Flatten each subimage into a 1D vector\n",
    "    flattened_descriptors = descriptors.reshape(descriptors.shape[0], -1)\n",
    "\n",
    "    # Remove subimages with NaN values\n",
    "    mask = ~np.isnan(flattened_descriptors).any(axis=1)\n",
    "    valid_subimages = flattened_descriptors[mask]\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=n_clusters)\n",
    "    reduced_data = pca.fit_transform(valid_subimages)\n",
    "\n",
    "    # Fit the preliminary GMM using valid subimages (without NaN values)\n",
    "    preliminary_gmm = GaussianMixture(n_components=components, covariance_type=covariance_type, random_state=42)\n",
    "    preliminary_gmm.fit(reduced_data)\n",
    "    initial_means = preliminary_gmm.means_\n",
    "    initial_weights = preliminary_gmm.weights_\n",
    "\n",
    "    # Initialize the GMM with the parameters from the preliminary fit\n",
    "    gmm = GaussianMixture(n_components=components,\n",
    "                          means_init=initial_means,\n",
    "                          weights_init=initial_weights,\n",
    "                          covariance_type=covariance_type,\n",
    "                          random_state=42)\n",
    "    gmm.fit(reduced_data)\n",
    "\n",
    "    # Predict labels for the valid subimages\n",
    "    labels = gmm.predict(reduced_data)\n",
    "\n",
    "    # Map the labels back to the original data, including NaN-handling\n",
    "    full_labels = np.full(flattened_descriptors.shape[0], -1)  # Initialize full labels with -1\n",
    "    full_labels[mask] = labels  # Only set labels for valid subimages\n",
    "\n",
    "    return full_labels, reduced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3a281-99f5-4d36-acaf-a227a9e980b6",
   "metadata": {
    "id": "A7LamZt9lUe2"
   },
   "source": [
    "## Select Image of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd12c5-29f2-4d10-a935-955b21f7a54c",
   "metadata": {
    "id": "HL2HllKeTvvQ"
   },
   "source": [
    "In this analysis, we focus on a selected STEM image from a larger dataset.\n",
    "1. Detecting Atomic Features in the STEM image using the blob_log function from skimage.feature identifies potential atomic positions using a Laplacian of Gaussian (LoG) approach.\n",
    "\n",
    "2. Extracting Subimages: using the detected coordinates, the function custom_extract_subimages is called to generate fixed-size subimages around each detected atomic feature.\n",
    "\n",
    "3. Flattening Subimages for Descriptor Generation: Each subimage is flattened into a one-dimensional array, creating a consistent descriptor format for further analysis or machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be918a4a-a1ea-4163-9030-e2d6e4ef532b",
   "metadata": {
    "id": "XL00GvBo4X0w"
   },
   "outputs": [],
   "source": [
    "image = selected_images[0]\n",
    "img = norm2d(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c17ef0",
   "metadata": {},
   "source": [
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df151e32-897e-4ac7-b83f-e4ad111ae2e8",
   "metadata": {
    "id": "thVLnQEX4X0w"
   },
   "outputs": [],
   "source": [
    "# window_size = (40,40)\n",
    "# min_sigma = 1\n",
    "# max_sigma = 5\n",
    "# threshold = 0.025\n",
    "# overlap = 0.0\n",
    "# descriptors, coms_target, all_atoms, coordinates, subimages_target = build_descriptor(window_size, min_sigma, max_sigma, threshold, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43bc750c-ad67-4533-821b-b37c9ae1cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(descriptors.shape)\n",
    "# print(coms_target.shape)\n",
    "# print(all_atoms.shape)\n",
    "# print(coordinates.shape)\n",
    "# print(subimages_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580adbd2-6911-40f2-ae16-759bd37326bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.scatter(coms_target[:, 1], coms_target[:, 0], c='r', marker='o', s = 20\n",
    "#             )\n",
    "# plt.axis('off')\n",
    "# plt.title('Image with Subimage Centers')\n",
    "# plt.xlim([300, 700])\n",
    "# plt.ylim([300, 700])\n",
    "# plt.show()\n",
    "\n",
    "# # Plot a few example subimages with their centers\n",
    "# fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(subimages_target[i], cmap='gray')\n",
    "#     ax.scatter(window_size[1] // 2, window_size[0] // 2, c='r', marker='o', s = 100)\n",
    "#     ax.set_title(f'Subimage {i+1}', fontweight = \"bold\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac2b13b-94d9-43cd-90f1-42fffc3eb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and visualize the average descriptor\n",
    "# average_descriptor = descriptors.mean(axis=0).reshape(window_size)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.imshow(average_descriptor, cmap='viridis')\n",
    "# plt.colorbar()\n",
    "# plt.title(\"Average Descriptor of All Subimages\")\n",
    "# # plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a945b24-48b0-43c6-9d24-244474d3f8c4",
   "metadata": {
    "id": "XnSB1TABNNAv"
   },
   "source": [
    "## GMM clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24ac3d-7ba9-4bfa-a3c3-970458ba4e28",
   "metadata": {
    "id": "Ns9kqa5bVsDC"
   },
   "source": [
    "Here, we’re applying clustering to the descriptors extracted from subimages to group similar structural features and then visualizing the clusters to better understand the patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b1d2b-95a7-48ec-a03e-5f6ff76cac07",
   "metadata": {
    "id": "pXycsMlfVxVW"
   },
   "source": [
    "Clustering with Gaussian Mixture Model (GMM)\n",
    "1. **GMM on Raw Descriptors (Fit_GMM)**:\n",
    "\n",
    "    The function Fit_GMM is applied directly to the descriptors, with 5 clusters specified and a \"full\" covariance type. This model assumes the data can be represented by a mixture of 5 Gaussian distributions with unrestricted covariance matrices (i.e., allowing each cluster to have its unique shape).\n",
    "\n",
    "    Outputs:\n",
    "    labels: Cluster labels assigned to each subimage, indicating the group each subimage belongs to.\n",
    "\n",
    "    valid_subimages: The subset of descriptors that were successfully clustered.\n",
    "2. **PCA and GMM Combined (Fit_PCA_GMM)**:\n",
    "\n",
    "    The Fit_PCA_GMM function applies Principal Component Analysis (PCA) to reduce the dimensionality of the descriptors from high-dimensional space down to 2 principal components (PCs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1059a5b",
   "metadata": {},
   "source": [
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6402fa24-5d10-41a8-b921-508fa6ce80cd",
   "metadata": {
    "id": "QUQaUjedNToN"
   },
   "outputs": [],
   "source": [
    "# labels, valid_subimages  = Fit_GMM(descriptors, 5, \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "704721f4-7cbf-4426-8469-a636061bb709",
   "metadata": {
    "id": "tZBwxh3OS7_C"
   },
   "outputs": [],
   "source": [
    "# labels_pca, reduced_data_pca  = Fit_PCA_GMM(descriptors, 2, 5, \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bca64fd-a621-42c4-a295-2ec6a00d9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig , axes = plt.subplots(1, 2 , figsize = (12, 5))\n",
    "\n",
    "# axes[0].scatter(valid_subimages[:, 0], valid_subimages[:, 1], c=labels, s=20, cmap='jet', edgecolor='k')\n",
    "# axes[0].set_title('GMM clustering' , fontsize = 16, fontweight = \"bold\")\n",
    "# axes[0].set_xlabel('C1')\n",
    "# axes[0].set_ylabel('C2')\n",
    "\n",
    "# axes[1].scatter(reduced_data_pca[:, 0], reduced_data_pca[:, 1], c=labels_pca, s=20, cmap='jet', edgecolor='k')\n",
    "# axes[1].set_title('GMM PCA clustering' , fontsize = 16, fontweight = \"bold\")\n",
    "# axes[1].set_xlabel('PC1')\n",
    "# axes[1].set_ylabel('PC2')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9eec29-8d55-4607-8da4-341c0bf74ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize lists to store the centroids and dispersions\n",
    "# cluster_centroids = []\n",
    "# cluster_dispersions = []\n",
    "\n",
    "# # Calculate the overall mean descriptor\n",
    "# overall_mean = descriptors.mean(axis=0)\n",
    "\n",
    "# # Calculate the centroids and dispersions for each cluster\n",
    "# for cluster_label in np.unique(labels):\n",
    "#     # Get descriptors for the current cluster\n",
    "#     cluster_descriptors = descriptors[labels == cluster_label]\n",
    "#     # Calculate centroid and dispersion (standard deviation) for each cluster\n",
    "#     centroid = cluster_descriptors.mean(axis=0) - overall_mean\n",
    "#     dispersion = cluster_descriptors.std(axis=0)\n",
    "#     # Append results\n",
    "#     cluster_centroids.append(centroid)\n",
    "#     cluster_dispersions.append(dispersion)\n",
    "\n",
    "# # Convert to NumPy arrays for easy handling\n",
    "# cluster_centroids = np.array(cluster_centroids)\n",
    "# cluster_dispersions = np.array(cluster_dispersions)\n",
    "\n",
    "# # Plot the centroids and dispersions\n",
    "# fig, axes = plt.subplots(2, len(cluster_centroids), figsize=(15, 10))\n",
    "\n",
    "# # First row: Cluster centroids (centered)\n",
    "# for i, ax in enumerate(axes[0]):\n",
    "#     centroid_image = cluster_centroids[i].reshape(window_size)\n",
    "#     im_centroid = ax.imshow(centroid_image, cmap='coolwarm', aspect='auto')\n",
    "#     ax.set_title(f'Cluster {i+1} Centroid', fontweight=\"bold\")\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # Second row: Cluster dispersions (standard deviation within each cluster)\n",
    "# for i, ax in enumerate(axes[1]):\n",
    "#     dispersion_image = cluster_dispersions[i].reshape(window_size)\n",
    "#     im_dispersion = ax.imshow(dispersion_image, cmap='viridis', aspect='auto')\n",
    "#     ax.set_title(f'Cluster {i+1} Dispersion', fontweight=\"bold\")\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # # Add colorbars for interpretation\n",
    "# # fig.colorbar(im_centroid, ax=axes[0], orientation='vertical', fraction=0.02, pad=0.04)\n",
    "# # fig.colorbar(im_dispersion, ax=axes[1], orientation='vertical', fraction=0.02, pad=0.04)\n",
    "\n",
    "# plt.suptitle(\"Cluster Centroids and Dispersion (Standard Deviation) Across Descriptors\", fontsize=16, fontweight=\"bold\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9758ce09-d8db-43f5-a7aa-31324d3187ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# # First subplot\n",
    "# ax[0].scatter(coms_target[:, 1], coms_target[:, 0], c=labels, s=10, cmap='jet', marker=\"s\")\n",
    "# ax[0].set_title('GMM' , fontsize = 16, fontweight = \"bold\")\n",
    "# ax[0].axis('off')\n",
    "\n",
    "# ax[1].scatter(coms_target[:, 1], coms_target[:, 0], c=labels_pca, s=10, cmap='jet', marker=\"s\")\n",
    "# ax[1].set_title('PCA GMM' , fontsize = 16, fontweight = \"bold\")\n",
    "# ax[1].axis('off')  # Just to leave it empty for now\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70513f1",
   "metadata": {},
   "source": [
    "### Interactive results for different window sizes and different number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1944c33c-a917-424d-aabe-80d820511186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_clustering with all involved hyprparameters\n",
    "\n",
    "def interactive_clustering(window_width, window_height, n_components, covariance_type):\n",
    "    # Parameters\n",
    "    window_size = (window_width, window_height)\n",
    "    min_sigma = 1\n",
    "    max_sigma = 5\n",
    "    threshold = 0.025\n",
    "    overlap = 0.0\n",
    "    \n",
    "    # Build descriptors and fit models\n",
    "    descriptors, coms_target, _, _, _ = build_descriptor(window_size, min_sigma, max_sigma, threshold, overlap)\n",
    "    descriptors = np.array(descriptors, dtype=np.float32)\n",
    "    coms_target = np.array(coms_target, dtype=np.float32)\n",
    "    \n",
    "    # Use the chosen covariance_type here\n",
    "    labels_gmm, subimages_gmm = Fit_GMM(descriptors, n_components, covariance_type)\n",
    "    labels_pca, subimages_pca = Fit_PCA_GMM(descriptors, 2, n_components, covariance_type)\n",
    "    \n",
    "    # Create a 2x2 plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    \n",
    "    # GMM Clusters\n",
    "    axes[0, 0].scatter(subimages_gmm[:, 0], subimages_gmm[:, 1], c=labels_gmm, s=20, cmap='jet', edgecolor='k')\n",
    "    axes[0, 0].set_title('GMM Clusters', fontsize=16, fontweight=\"bold\")\n",
    "    axes[0, 0].set_xlabel('C1')\n",
    "    axes[0, 0].set_ylabel('C2')\n",
    "\n",
    "    # PCA Clusters\n",
    "    axes[0, 1].scatter(subimages_pca[:, 0], subimages_pca[:, 1], c=labels_pca, s=20, cmap='jet', edgecolor='k')\n",
    "    axes[0, 1].set_title('PCA GMM Clusters', fontsize=16, fontweight=\"bold\")\n",
    "    axes[0, 1].set_xlabel('PC1')\n",
    "    axes[0, 1].set_ylabel('PC2')\n",
    "\n",
    "    # GMM Final Maps\n",
    "    axes[1, 0].scatter(coms_target[:, 1], coms_target[:, 0], c=labels_gmm, s=8, cmap='jet', marker=\"s\")\n",
    "    axes[1, 0].set_title('GMM Final Map', fontsize=16, fontweight=\"bold\")\n",
    "    axes[1, 0].axis('off')\n",
    "\n",
    "    # PCA Final Maps\n",
    "    axes[1, 1].scatter(coms_target[:, 1], coms_target[:, 0], c=labels_pca, s=8, cmap='jet', marker=\"s\")\n",
    "    axes[1, 1].set_title('PCA Final Map', fontsize=16, fontweight=\"bold\")\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9e113d0-52f9-48e4-9774-f2aa48890a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ffa81f843a4fcf968aed4cba60135b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, continuous_update=False, description='Width', max=64, min=2, step=2),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_clustering(window_width, window_height, n_components, covariance_type)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: app:gmm_widget_1_updated\n",
    "\n",
    "ipywidgets.interact(\n",
    "    interactive_clustering, \n",
    "    window_width=ipywidgets.IntSlider(min=2, max=64, step=2, value=2, description='Width', continuous_update=False),\n",
    "    window_height=ipywidgets.IntSlider(min=2, max=64, step=2, value=2, description='Height', continuous_update=False),\n",
    "    n_components=ipywidgets.IntSlider(min=2, max=6, step=1, value=2, description='Components', continuous_update=False),\n",
    "    covariance_type = ipywidgets.SelectionSlider(options=['full', 'tied', 'diag', 'spherical'], value=\"full\", description=\"Covariance Type\", continuous_update=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b63801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ferro_VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
